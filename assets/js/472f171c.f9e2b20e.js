"use strict";(self.webpackChunkkahunakv_docs=self.webpackChunkkahunakv_docs||[]).push([[8440],{1324:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"distributed-keyvalue-store/buckets","title":"Key Distribution and Buckets","description":"Regular Key Distribution","source":"@site/docs/distributed-keyvalue-store/buckets.md","sourceDirName":"distributed-keyvalue-store","slug":"/distributed-keyvalue-store/buckets","permalink":"/docs/distributed-keyvalue-store/buckets","draft":false,"unlisted":false,"editUrl":"https://github.com/kahunakv/kahunakv.github.io/tree/main/docs/distributed-keyvalue-store/buckets.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Revisions","permalink":"/docs/distributed-keyvalue-store/revisions"},"next":{"title":"Transactions","permalink":"/docs/distributed-keyvalue-store/transactions"}}');var i=n(4848),r=n(8453);const a={},c="Key Distribution and Buckets",o={},d=[{value:"Regular Key Distribution",id:"regular-key-distribution",level:2},{value:"Bucket Distribution",id:"bucket-distribution",level:2},{value:"Get by Prefix",id:"get-by-prefix",level:2},{value:"Example:",id:"example",level:3}];function l(e){const s={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"key-distribution-and-buckets",children:"Key Distribution and Buckets"})}),"\n",(0,i.jsx)(s.h2,{id:"regular-key-distribution",children:"Regular Key Distribution"}),"\n",(0,i.jsxs)(s.p,{children:["Keys, when stored, are distributed across the various nodes over all available partitions. A Kahuna cluster can have dozens, hundreds, or even thousands of partitions spread across active nodes. This ensures that each node acts as a ",(0,i.jsx)(s.strong,{children:"leader for multiple partitions"})," and a ",(0,i.jsx)(s.strong,{children:"follower for others"}),"."]}),"\n",(0,i.jsxs)(s.p,{children:["The ability of a node to be both a leader and a follower simultaneously allows responsibilities to be distributed, enables read and write operations to be accepted from any node, and maximizes the use of the ",(0,i.jsx)(s.strong,{children:"full compute capacity"})," available in the cluster."]}),"\n",(0,i.jsxs)(s.p,{children:["The algorithm used to decide which partition a key is assigned to is a ",(0,i.jsx)(s.strong,{children:"range-based consistent hashing"})," strategy. The entire keyspace is divided into ranges according to the number of active partitions."]}),"\n",(0,i.jsxs)(s.p,{children:["For example, if the keyspace spans from ",(0,i.jsx)(s.code,{children:"0"})," to ",(0,i.jsx)(s.code,{children:"1024"})," and there are ",(0,i.jsx)(s.strong,{children:"8 partitions"}),", the distribution would look like this:"]}),"\n",(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:(0,i.jsx)(s.strong,{children:"Partition"})}),(0,i.jsx)(s.th,{children:(0,i.jsx)(s.strong,{children:"Range"})})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 0"}),(0,i.jsx)(s.td,{children:"0\u2013127"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 1"}),(0,i.jsx)(s.td,{children:"128\u2013255"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 2"}),(0,i.jsx)(s.td,{children:"256\u2013383"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 3"}),(0,i.jsx)(s.td,{children:"384\u2013511"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 4"}),(0,i.jsx)(s.td,{children:"512\u2013639"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 5"}),(0,i.jsx)(s.td,{children:"640\u2013767"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 6"}),(0,i.jsx)(s.td,{children:"768\u2013895"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Partition 7"}),(0,i.jsx)(s.td,{children:"896\u20131024"})]})]})]}),"\n",(0,i.jsxs)(s.p,{children:["Each key is hashed into this keyspace, and the resulting hash determines which partition it falls into. This approach provides ",(0,i.jsx)(s.strong,{children:"balanced distribution"}),", supports ",(0,i.jsx)(s.strong,{children:"scalability"}),", and simplifies ",(0,i.jsx)(s.strong,{children:"rebalancing"})," when partitions are added or removed."]}),"\n",(0,i.jsxs)(s.p,{children:["Now, based on the distribution above, let\u2019s say we want to store the key named ",(0,i.jsx)(s.code,{children:"my-config"}),":"]}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-swift",children:'set `my-config` "ab10a9bc1924cd"\nr0 set 10ms\n'})}),"\n",(0,i.jsxs)(s.p,{children:["By computing the consistent hash: ",(0,i.jsx)(s.code,{children:'CH("my-config") = 471'}),",",(0,i.jsx)(s.br,{}),"\n","we determine that it falls within the range ",(0,i.jsx)(s.code,{children:"384\u2013511"}),",",(0,i.jsx)(s.br,{}),"\n","which means its ",(0,i.jsx)(s.strong,{children:"assigned partition is partition 3"}),"."]}),"\n",(0,i.jsxs)(s.p,{children:["This allows Kahuna to ",(0,i.jsx)(s.strong,{children:"route the key to the correct leader node"})," for partition 3 and ensure all operations on ",(0,i.jsx)(s.code,{children:"my-config"})," are handled consistently and efficiently."]}),"\n",(0,i.jsx)(s.h2,{id:"bucket-distribution",children:"Bucket Distribution"}),"\n",(0,i.jsx)(s.p,{children:"Kahuna provides a way to force a group of different keys to be stored in the same partition. By prefixing the keys with a common bucket, you indicate to the hashing algorithm that this bucket should be used to determine the partition associated with the key."}),"\n",(0,i.jsxs)(s.p,{children:["This means that all keys sharing the same bucket prefix\u2014such as ",(0,i.jsx)(s.code,{children:"services/auth"}),", ",(0,i.jsx)(s.code,{children:"services/matchmaking"})," and ",(0,i.jsx)(s.code,{children:"services/inventory"})," be routed to the same partition, allowing for more efficient transaction execution and reduced cross-partition communication."]}),"\n",(0,i.jsxs)(s.p,{children:["In the following example, all keys share a common bucket prefix ",(0,i.jsx)(s.code,{children:"services"}),", and therefore they are hashed to the ",(0,i.jsx)(s.strong,{children:"same partition"}),":"]}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-ruby",children:'set "services/auth" "localhost:8081"\nset "services/matchmaking" "localhost:8082"\nset "services/inventory" "localhost:8083"\n'})}),"\n",(0,i.jsxs)(s.p,{children:["Because they all begin with the ",(0,i.jsx)(s.code,{children:"services/"})," bucket, the consistent hashing algorithm treats them as part of the ",(0,i.jsx)(s.strong,{children:"same logical group"}),", ensuring that they reside in the ",(0,i.jsx)(s.strong,{children:"same partition"}),":"]}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-txt",children:'services/auth  \n-------- ----\n^ bucket ^ key\n\nservices/matchmaking  \n-------- -----------\n^ bucket    ^ key\n\nservices/inventory\n-------- ---------\n^ bucket   ^ key\n\nCH("services") -> 5\n'})}),"\n",(0,i.jsx)(s.h2,{id:"get-by-prefix",children:"Get by Prefix"}),"\n",(0,i.jsxs)(s.p,{children:["The fact that all keys are in the same ",(0,i.jsx)(s.strong,{children:"bucket"})," and ",(0,i.jsx)(s.strong,{children:"partition"})," allows the use of the ",(0,i.jsx)(s.code,{children:"get by prefix"})," operation, which ",(0,i.jsx)(s.strong,{children:"consistently returns all keys"})," belonging to the specified bucket."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Example:"})}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-ruby",children:'let configs = get by prefix "services"\n'})}),"\n",(0,i.jsxs)(s.p,{children:["This retrieves all keys that start with ",(0,i.jsx)(s.code,{children:"services/"}),", such as:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.code,{children:"services/auth"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.code,{children:"services/matchmaking"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.code,{children:"services/inventory"})}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Because they reside in the ",(0,i.jsx)(s.strong,{children:"same partition"}),", this operation is efficient, strongly consistent, and avoids the complexity of querying across multiple partitions and nodes."]}),"\n",(0,i.jsxs)(s.p,{children:["Since ",(0,i.jsx)(s.code,{children:"get by prefix"})," is a ",(0,i.jsx)(s.strong,{children:"consistent operation"}),", it can also be part of a ",(0,i.jsx)(s.strong,{children:"transaction"}),". When used within a transaction, it generates ",(0,i.jsx)(s.strong,{children:"MVCC (Multi-Version Concurrency Control) entries"}),", providing ",(0,i.jsx)(s.strong,{children:"snapshot isolation"}),". The keys read and modified during the transaction will only be committed if the transaction completes successfully\u2014otherwise, the changes will be discarded."]}),"\n",(0,i.jsx)(s.h3,{id:"example",children:"Example:"}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-ruby",children:'# Initial setup\nset "services/auth" "localhost:8081"\nset "services/matchmaking" "localhost:8082"\nset "services/inventory" "localhost:8083"\n'})}),"\n",(0,i.jsx)(s.p,{children:"Later, inside a transaction:"}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-ruby",children:'let all_services = get by prefix "services"\nif contains(all_services, "services/users") then\n  set "services/users" "localhost:8084"\nend\n\nlet all_services = get by prefix "services"\nif contains(all_services, "services/users") then\n  return true\nend\n\nreturn false\n'})}),"\n",(0,i.jsx)(s.p,{children:"In this example:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["The first ",(0,i.jsx)(s.code,{children:"get by prefix"})," reads a ",(0,i.jsx)(s.strong,{children:"consistent snapshot"})," of all keys under ",(0,i.jsx)(s.code,{children:"services/"}),"."]}),"\n",(0,i.jsxs)(s.li,{children:["The logic conditionally adds a new service only if ",(0,i.jsx)(s.code,{children:'"services/users"'})," doesn\u2019t already exist."]}),"\n",(0,i.jsxs)(s.li,{children:["The second ",(0,i.jsx)(s.code,{children:"get by prefix"})," confirms whether the new key is present ",(0,i.jsx)(s.strong,{children:"within the same transactional snapshot"}),"."]}),"\n",(0,i.jsx)(s.li,{children:"If the transaction commits, all changes become visible atomically; if it fails, none are applied."}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["This showcases how ",(0,i.jsx)(s.code,{children:"get by prefix"})," can be safely used for ",(0,i.jsx)(s.strong,{children:"multi-key logic"})," inside transactional flows."]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>c});var t=n(6540);const i={},r=t.createContext(i);function a(e){const s=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:s},e.children)}}}]);